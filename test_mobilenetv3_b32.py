# -*- coding: utf-8 -*-
"""Test_MobileNetV3-B32.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RwOIOuGKVdVtwGSNM4h0KXRETdimlnCK
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader, Subset
from transformers import ViTForImageClassification
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from torch.optim.lr_scheduler import OneCycleLR
from torch.nn.utils import clip_grad_norm_

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

train_transform = transforms.Compose([
    transforms.RandomResizedCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(20),
    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),
    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

test_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

dataset_path = '/content/drive/MyDrive/monkey/'
train_dataset = datasets.ImageFolder(root=dataset_path + 'train', transform=train_transform)
val_dataset = datasets.ImageFolder(root=dataset_path + 'validation', transform=test_transform)
test_dataset = datasets.ImageFolder(root=dataset_path + 'test', transform=test_transform)

train_size = len(train_dataset)
indices = list(range(train_size))
np.random.shuffle(indices)
split = train_size // 3
client_datasets = [Subset(train_dataset, indices[i:i+split]) for i in range(0, train_size, split)]

batch_size = 16
client_loaders = [DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=2) for ds in client_datasets]
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)

class MobileNetV3_ViTB32_Hybrid(nn.Module):
    def __init__(self, num_classes=2):
        super(MobileNetV3_ViTB32_Hybrid, self).__init__()

        self.cnn = models.mobilenet_v3_large(pretrained=True)
        self.cnn.classifier = nn.Identity()

        self.vit = ViTForImageClassification.from_pretrained('google/vit-base-patch32-224-in21k')
        self.vit.classifier = nn.Identity()

        self.fc = nn.Sequential(
            nn.Linear(960 + 768, 1024),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(1024, 512),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(512, num_classes)
        )

    def forward(self, x):
        cnn_features = self.cnn(x)
        vit_outputs = self.vit(pixel_values=x).logits
        combined_features = torch.cat((cnn_features, vit_outputs), dim=1)
        return self.fc(combined_features)

def train_client(model, train_loader, optimizer, criterion, epochs, scheduler):
    model.train()

    layers_to_unfreeze = [
        model.cnn.features[-3],
        model.cnn.features[-2],
        model.cnn.features[-1],
        model.vit.vit.encoder.layer[-1],
        model.vit.vit.encoder.layer[-2],
    ]

    for param in model.parameters():
        param.requires_grad = False
    for param in model.fc.parameters():
        param.requires_grad = True

    for epoch in range(epochs):
        if epoch < len(layers_to_unfreeze):
            for param in layers_to_unfreeze[epoch].parameters():
                param.requires_grad = True

        for batch_idx, (inputs, labels) in enumerate(train_loader):
            inputs, labels = inputs.to(device), labels.to(device)
            inputs, labels_a, labels_b, lam = mixup_data(inputs, labels)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)
            loss.backward()
            clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
            scheduler.step()

    return model.state_dict()

def aggregate_models(client_models):
    aggregated_model = {}
    for key in client_models[0].keys():
        aggregated_model[key] = sum(client_model[key] for client_model in client_models) / len(client_models)
    return aggregated_model

def evaluate_model(model, data_loader, criterion):
    model.eval()
    total_loss = 0
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for inputs, labels in data_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            total_loss += loss.item()
            _, preds = torch.max(outputs, 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    avg_loss = total_loss / len(data_loader)
    accuracy = accuracy_score(all_labels, all_preds)
    precision = precision_score(all_labels, all_preds, average='weighted')
    recall = recall_score(all_labels, all_preds, average='weighted')
    f1 = f1_score(all_labels, all_preds, average='weighted')

    return avg_loss, accuracy, precision, recall, f1

def federated_learning(num_rounds, local_epochs, patience=5):
    global_model = ResNet18_ViTB16_Hybrid(num_classes=2).to(device)
    criterion = nn.CrossEntropyLoss()
    best_val_accuracy = 0
    rounds_without_improvement = 0
    best_model_state = None

    for round in range(num_rounds):
        client_models = []

        for client_loader in client_loaders:
            client_model = ResNet18_ViTB16_Hybrid(num_classes=2).to(device)
            client_model.load_state_dict(global_model.state_dict())
            optimizer = optim.AdamW(client_model.parameters(), lr=1e-3, weight_decay=1e-4)

            scheduler = OneCycleLR(optimizer, max_lr=1e-3, steps_per_epoch=len(client_loader), epochs=local_epochs)

            client_state_dict = train_client(client_model, client_loader, optimizer, criterion, local_epochs, scheduler)
            client_models.append(client_state_dict)

        global_model_dict = aggregate_models(client_models)
        global_model.load_state_dict(global_model_dict)

        val_loss, val_accuracy, val_precision, val_recall, val_f1 = evaluate_model(global_model, val_loader, criterion)
        print(f"Round {round+1}/{num_rounds}")
        print(f"Validation - Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}")

        if val_accuracy > best_val_accuracy:
            best_val_accuracy = val_accuracy
            best_model_state = global_model.state_dict()
            rounds_without_improvement = 0
        else:
            rounds_without_improvement += 1

        if rounds_without_improvement >= patience:
            print(f"Early stopping triggered after {round+1} rounds")
            break

    global_model.load_state_dict(best_model_state)

    test_loss, test_accuracy, test_precision, test_recall, test_f1 = evaluate_model(global_model, test_loader, criterion)
    print("\nFinal Test Results:")
    print(f"Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}")

federated_learning(num_rounds=25, local_epochs=5, patience=3)